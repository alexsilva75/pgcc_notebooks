{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23060eeb-63a5-4842-92aa-2d57adedffce",
   "metadata": {},
   "source": [
    "## PyTorch CNN Visualizations\n",
    "https://github.com/utkuozbulak/pytorch-cnn-visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a79c0e-ee0d-4540-883c-5fec0b2a66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchinfo import summary\n",
    "import cam.misc_functions\n",
    "import cam.scorecam\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6869ebc5-6257-4cf0-9f32-f0eeaf8cd665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "VGG                                      --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       1,792\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Conv2d: 2-3                       36,928\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─MaxPool2d: 2-5                    --\n",
       "│    └─Conv2d: 2-6                       73,856\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Conv2d: 2-8                       147,584\n",
       "│    └─ReLU: 2-9                         --\n",
       "│    └─MaxPool2d: 2-10                   --\n",
       "│    └─Conv2d: 2-11                      295,168\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─Conv2d: 2-13                      590,080\n",
       "│    └─ReLU: 2-14                        --\n",
       "│    └─Conv2d: 2-15                      590,080\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─MaxPool2d: 2-17                   --\n",
       "│    └─Conv2d: 2-18                      1,180,160\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─Conv2d: 2-20                      2,359,808\n",
       "│    └─ReLU: 2-21                        --\n",
       "│    └─Conv2d: 2-22                      2,359,808\n",
       "│    └─ReLU: 2-23                        --\n",
       "│    └─MaxPool2d: 2-24                   --\n",
       "│    └─Conv2d: 2-25                      2,359,808\n",
       "│    └─ReLU: 2-26                        --\n",
       "│    └─Conv2d: 2-27                      2,359,808\n",
       "│    └─ReLU: 2-28                        --\n",
       "│    └─Conv2d: 2-29                      2,359,808\n",
       "│    └─ReLU: 2-30                        --\n",
       "│    └─MaxPool2d: 2-31                   --\n",
       "├─AdaptiveAvgPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-32                      102,764,544\n",
       "│    └─ReLU: 2-33                        --\n",
       "│    └─Dropout: 2-34                     --\n",
       "│    └─Linear: 2-35                      16,781,312\n",
       "│    └─ReLU: 2-36                        --\n",
       "│    └─Dropout: 2-37                     --\n",
       "│    └─Linear: 2-38                      4,097,000\n",
       "=================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  models.vgg16(weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1, progress=True)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297ceb12-7b06-495a-89f1-4d78dff0b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.features:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1518cd-9505-48b8-bd71-52015b2d47e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=25088, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=4096, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.classifier:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1921da8-4f3f-4a01-bfc9-268706fc7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.Resize(size=(224,224))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfdb6083-7da3-4ed0-8a3b-3fbec49cdc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./data/img/0_Amiloidose_HE_0.jpg')\n",
    "x = transf(image)\n",
    "x = TF.to_tensor(x)\n",
    "x.unsqueeze_(0)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833e288b-534c-496a-b0d9-949c9a174013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAM: 2340.6705882352935\n",
      "Layer index: 0\n",
      "Layer Description: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for layer in model.features:\n",
    "    score_cam = cam.scorecam.ScoreCam(model, i)\n",
    "    camap = torch.tensor(score_cam.generate_cam(x, 1))\n",
    "    print(f\"CAM: {torch.absolute(camap).sum().item()}\")    \n",
    "    print(f\"Layer index: {i}\")\n",
    "    print(f\"Layer Description: {str(layer)}\")\n",
    "    i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccf761-b8fa-4537-8a70-d2e330ea2141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
